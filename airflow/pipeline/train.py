import os
import logging
import argparse
import joblib
import numpy as np
import pandas as pd
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import average_precision_score

logging.basicConfig(level=logging.INFO)

if __name__ =='__main__':
    parser = argparse.ArgumentParser()
    # hyperparameters sent by the client are passed as command-line arguments to the script.
    parser.add_argument('--alpha', type=float, default=0.0001)
    parser.add_argument('--l1_ratio', type=float, default=0.15)

    # Data, model, and output directories
    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))
    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))
    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))
    parser.add_argument('--train-file', type=str)
    parser.add_argument('--test-file', type=str)
    parser.add_argument('--features', type=str)
    parser.add_argument('--target', type=str)

    args, _ = parser.parse_known_args()

    logging.info('reading data')
    chunksize = 20000
    train_df = pd.read_csv(os.path.join(args.train, args.train_file),
                           chunksize=chunksize,
                           iterator=True,
                           engine='python')
    test_df = pd.read_csv(os.path.join(args.test, args.test_file),
                          chunksize=chunksize,
                          iterator=True,
                          engine='python')

    # TRAIN
    logging.info('training model')

    model = SGDClassifier(loss='log', penalty='elasticnet', alpha=args.alpha,
                            l1_ratio=args.l1_ratio, shuffle=True, n_jobs=-1)
    for chunk in train_df:
        model.partial_fit(chunk[args.features.split()],
                          chunk[args.target],
                          classes=[0.0, 1.0])

    # LOG COUPLE PERF METRICS
    logging.info('evaluating model')
    y_true = pd.Series(dtype=float)
    for chunk in test_df:
        if y_true.empty:
            y_scores = model.predict(chunk[args.features.split()])
            y_true = chunk[args.target]
        else:
            y_scores = np.concatenate([y_scores, model.predict(chunk[args.features.split()])])
            y_true = pd.concat([y_true, chunk[args.target]])

    logging.info(f'chunk: {chunk}')
    logging.info(f'len(chunk): {len(chunk)}')
    logging.info(f'y_true: {y_true}, y_scores: {y_scores}')
    logging.info(f'avg-precision: {average_precision_score(y_true, y_scores)}')

    # Save model
    path = os.path.join(args.model_dir, 'model.joblib')
    joblib.dump(model, path)
    print(f'Model saved to {path}')