{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6650e5ea-ac22-4382-afe8-cdb50639fb77",
   "metadata": {},
   "source": [
    "# Train and Tune a Classifier for Network Traffic Data\n",
    "\n",
    "This Jupyter notebook outlines the steps to train and tune a classifier for classifying network traffic data as malignant or benign. We will be utilizing Amazon Sagemaker for training and deploying the model, and MLflow for tracking experiments and managing the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa40cc-ae48-40bf-8a1c-32edec52da40",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we need to set up our environment by installing necessary packages and importing required libraries.\n",
    "\n",
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3a695-9d95-423c-b18a-196f0026efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install s3fs to interact with S3 storage\n",
    "!pip install -q s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c2e92",
   "metadata": {},
   "source": [
    "### Import Libraries and Set Up Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cbd1e2-2b7c-4f1f-bab1-3962c217218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import Optional\n",
    "\n",
    "import boto3\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import (\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    "    TuningJobCompletionCriteriaConfig,\n",
    ")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set S3 bucket\n",
    "bucket_name = \"<name-of-your-s3-bucket>\"\n",
    "\n",
    "# Set up the Sagemaker session, role, and region\n",
    "sess = sagemaker.Session(default_bucket=bucket_name)\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "# Set up MLflow tracking\n",
    "tracking_uri = \"<uri-of-your-remote-mlflow-server>\"\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1172a8b-9677-4e38-b675-ef51edd47f73",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we train the model, we need to retrieve the latest training and testing data from our data storage.\n",
    "\n",
    "### Get Latest Data Files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4100b-dc3e-478f-928a-109322bd2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_csv_s3_path(bucket_name: str, prefix: str = \"\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Finds the latest CSV file within a specified prefix of an S3 bucket.\n",
    "\n",
    "    This function lists all objects in the given S3 bucket that match the\n",
    "    specified prefix. It filters for CSV files, identifies the most recently\n",
    "    modified CSV file, and returns its S3 path. If no CSV files are found under\n",
    "    the given prefix, the function returns None.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket to search.\n",
    "        prefix (str, optional): The prefix path within the S3 bucket to search\n",
    "                                under. Defaults to an empty string, meaning it\n",
    "                                will search the entire bucket.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The S3 path of the latest CSV file if found, None\n",
    "                       otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize a boto3 S3 resource to interact with S3 services\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "\n",
    "    # Access the specified S3 bucket using its name\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    # Initialize a list to store details of CSV files found\n",
    "    csv_files = []\n",
    "\n",
    "    # Iterate over objects in the specified bucket and prefix\n",
    "    for obj in bucket.objects.filter(Prefix=prefix):\n",
    "        # Check if the object key (file name) ends is a CSV file\n",
    "        if obj.key.endswith(\".csv\"):\n",
    "            # Append a tuple of (last_modified, key) for each CSV file\n",
    "            csv_files.append((obj.last_modified, obj.key))\n",
    "\n",
    "    # Sort the list of CSV files by their timestamp in descending order\n",
    "    csv_files.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Check if there are any CSV files found\n",
    "    if csv_files:\n",
    "        # Extract the key of the most recently modified CSV file\n",
    "        latest_csv_key = csv_files[0][1]\n",
    "        # Construct and return the S3 path for the latest CSV file\n",
    "        return f\"s3://{bucket_name}/{latest_csv_key}\"\n",
    "    else:\n",
    "        # Return None if no CSV files were found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c09654-a6ca-493f-9599-abaa1cd58ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to get paths to the latest training and testing data\n",
    "train_path = get_latest_csv_s3_path(bucket_name, \"train/\")\n",
    "test_path = get_latest_csv_s3_path(bucket_name, \"test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af519e88-e23d-4893-bc71-b73e871fec23",
   "metadata": {},
   "source": [
    "## Model Training and Hyperparameter Tuning\n",
    "\n",
    "Now, we will define the hyperparameters for our model, specify the hyperparameter tuning job, and start the training.\n",
    "\n",
    "### Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82aaba-c411-497d-bfff-e2cb3c2be41d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters and metric definitions for training\n",
    "hyperparameters = {\n",
    "    \"tracking_uri\": tracking_uri,\n",
    "    \"experiment_name\": \"malware-detection\",\n",
    "    \"features\": \" \".join(list(train_df.drop([\"test_set\", \"label\"], axis=1).columns)),\n",
    "    \"target\": \"label\",\n",
    "    \"train-file\": \"part-00000-d7be48fa-a5ba-4845-8b60-aeea62104ca3-c000.csv\",\n",
    "    \"test-file\": \"part-00000-d5acbcbf-4309-46e1-a30b-61ee99e02734-c000.csv\",\n",
    "}\n",
    "\n",
    "metric_definitions = [{\"Name\": \"avg-precision\", \"Regex\": \"avg-precision: ([0-9.]+).*$\"}]\n",
    "\n",
    "# Initialize the estimator and tuner\n",
    "estimator = SKLearn(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    source_dir=\"source_dir\",\n",
    "    entry_point=\"train.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    framework_version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0.00001, 0.001),\n",
    "    \"l1_ratio\": ContinuousParameter(0.0, 1.0),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"avg-precision\"\n",
    "objective_type = \"Maximize\"\n",
    "completion_criteria_config = TuningJobCompletionCriteriaConfig(\n",
    "    complete_on_convergence=True\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=4,\n",
    "    objective_type=objective_type,\n",
    "    completion_criteria_config=completion_criteria_config,\n",
    "    base_tuning_job_name=\"mlflow\",\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning job\n",
    "tuner.fit({\"train\": f\"s3://{bucket_name}/train\", \"test\": f\"s3://{bucket_name}/test\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c936ace-b677-4e60-acda-5c715e1364a0",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "After training, we need to build a container for serving the model and deploy it as an endpoint on SageMaker.\n",
    "\n",
    "### Build MLflow Docker Image for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffa8aa-36a9-4a39-a9fe-045369f54ebc",
   "metadata": {},
   "source": [
    "In your console, run these commands to build and push the MLflow Docker image:\n",
    "\n",
    "```bash\n",
    "export AWS_ACCESS_KEY_ID=\n",
    "export AWS_SECRET_ACCESS_KEY=\n",
    "export AWS_SESSION_TOKEN=\n",
    "export AWS_DEFAULT_REGION=us-east\n",
    "mlflow sagemaker build-and-push-container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b51cd-5cfe-4742-9ebb-1bd79e8194d1",
   "metadata": {},
   "source": [
    "### Deploy the Model to a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcbb0a-1630-46c7-8f6e-f9ef4e599033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define deployment configurations\n",
    "image_uri = \"<URL of the ECR-hosted Docker image>\"\n",
    "endpoint_name = \"malware-detection\"\n",
    "# The location, in URI format, of the MLflow model to deploy to SageMaker.\n",
    "model_uri = \"models:/malware-detection/latest\"\n",
    "\n",
    "config = {\n",
    "    \"execution_role_arn\": role,\n",
    "    \"image_url\": image_uri,\n",
    "    \"instance_type\": \"ml.m5.xlarge\",\n",
    "    \"instance_count\": 1,\n",
    "    \"region_name\": region,\n",
    "}\n",
    "\n",
    "# Deploy the model to SageMaker\n",
    "client = get_deploy_client(\"sagemaker\")\n",
    "client.create_deployment(\n",
    "    name=endpoint_name, model_uri=model_uri, flavor=\"python_function\", config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336ddd5-1bb7-4b32-b258-51da40fcb479",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "With the model deployed, we can now send data to the endpoint to make predictions.\n",
    "\n",
    "### Predict with the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450d545-848e-4627-8d16-76baae9be26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from the test data\n",
    "for df in pd.read_csv(test_path, chunksize=10000, iterator=True):\n",
    "    if sum(df[\"label\"]) > 0:\n",
    "        # Selecting a specific data point for prediction\n",
    "        df = df.loc[df[\"label\"] == 1.0]\n",
    "        df = df.iloc[[26]]\n",
    "        break\n",
    "\n",
    "ground_truth = df[\"label\"]\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c5d3e-50de-4a1d-9276-e72563e71913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"test_set\", \"label\"], axis=1)\n",
    "\n",
    "# Make predictions using the deployed endpoint\n",
    "client = get_deploy_client(f\"sagemaker:/{region}\")\n",
    "prediction = client.predict(endpoint_name, df)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f770db-4675-4a22-9039-8c45c1d4f3bc",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "After we're done, it's good practice to clean up the resources we created to avoid incurring unnecessary costs.\n",
    "\n",
    "### Delete the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c07ba9-d785-405b-af10-ab76597cf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "client.delete_deployment(endpoint_name, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
